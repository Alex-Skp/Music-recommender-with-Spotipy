{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fantastic-lightning",
   "metadata": {},
   "source": [
    "# One step further, for a massive database of songs \n",
    "# WARNING: Big loading times zone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "configured-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from getpass import getpass\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import random "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chinese-determination",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "c_id = str(getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rural-satellite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "c_s = str(getpass())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demonstrated-moses",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=c_id,\n",
    "                                                          client_secret=c_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-given",
   "metadata": {},
   "source": [
    "We test that is running properly. We will start taking a list of categories. We test if the calls work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-ethiopia",
   "metadata": {},
   "source": [
    "And we put our categories together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "computational-picnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for cat in sp.categories(limit = 50)['categories']['items']:\n",
    "    categories.append(cat['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "seven-imaging",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "rough-ivory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f0cc592e7a41989f49a223926c00d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/39 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "playlist_id = []\n",
    "for cat in tqdm(categories):\n",
    "    try:\n",
    "        i=0\n",
    "        cat_data = sp.category_playlists(cat, limit = 50, offset=i)['playlists']['items']\n",
    "        #Having this while loop will allow retrieve more than 50 per category \n",
    "        while len(cat_data) == i+50:\n",
    "            i +=50\n",
    "            cat_data += sp.category_playlists(cat, limit = 50, offset=i)['playlists']['items']   \n",
    "    except:\n",
    "        continue\n",
    "    for plist in cat_data:\n",
    "        try:\n",
    "            playlist_id.append(plist['id'])\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "affected-marathon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "793"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "previous-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint1:saving playlist_id\n",
    "out_playlist_id = pd.Series(playlist_id, name='playlist_id')\n",
    "out_playlist_id.to_csv(\"../data/checkpoints/checkpoint_playlist_id.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pacific-diana",
   "metadata": {},
   "source": [
    "Here we will take all artist ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "labeled-scroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4b095a56e34ac4bf737bc0c20ecfe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/793 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "artist_ids = []\n",
    "for plist in tqdm(playlist_id):\n",
    "    i = 0\n",
    "    tracks = sp.playlist_tracks(plist, limit=100, offset=i)['items']\n",
    "    while len(tracks)==i+100:\n",
    "        i += 100\n",
    "        tracks += sp.playlist_tracks(plist, limit=100, offset=i)['items']\n",
    "    for track in tracks:\n",
    "        try:\n",
    "            for ids in [artist['id'] for artist in track['track']['artists']]:\n",
    "                artist_ids.append(ids)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-there",
   "metadata": {},
   "source": [
    "Removing duplicated ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "compressed-darwin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28227\n"
     ]
    }
   ],
   "source": [
    "artist_ids = list(set(artist_ids))\n",
    "print(len(artist_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "seasonal-poison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint2:saving artist_ids\n",
    "out_artist_ids = pd.Series(artist_ids, name='artist_ids')\n",
    "out_artist_ids.to_csv(\"../data/checkpoints/checkpoint_artist_ids.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-beads",
   "metadata": {},
   "source": [
    "And shuffle the list to reduce bias from the sample recovered. If it is not shuffled, the playlists from certain category would be taken first and the categories towards the end, as this script takes a lot of time to complete, won't be considered. This way we can run the script to gather as much data as we can in the period of time, and will be tracks from random artists instead of the ones from certain category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "utility-worcester",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(artist_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-bosnia",
   "metadata": {},
   "source": [
    "Now we get a list of all their albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "applicable-cleanup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a322dca50dc45ecababce2385d6fd29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/28227 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "album_ids = []\n",
    "\n",
    "for artist in tqdm(artist_ids):\n",
    "        i = 0\n",
    "        albums = sp.artist_albums(artist, limit=50, offset=i)['items']\n",
    "        while len(albums)==i+50:\n",
    "            i += 50\n",
    "            albums += sp.artist_albums(artist, limit=50, offset=i)['items']\n",
    "        for album in albums:\n",
    "            album_ids.append(album['id'])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-lancaster",
   "metadata": {},
   "source": [
    "Again, removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "executed-nature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2687991"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(album_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fabulous-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1110365"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album_ids = list(set(album_ids))\n",
    "len(album_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "through-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint2:saving artist_ids\n",
    "out_album_ids = pd.Series(album_ids, name='album_ids')\n",
    "out_album_ids.to_csv(\"../data/checkpoints/checkpoint_album_ids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cordless-insulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(album_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-variable",
   "metadata": {},
   "source": [
    "Going through every album and extracting the track information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "demonstrated-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eea26988ef44e70b6a8dcaf6b95c8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1110365 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "song_id = []\n",
    "song_name = []\n",
    "song_artists = []\n",
    "\n",
    "\n",
    "\n",
    "for album in tqdm(album_ids):\n",
    "    try:\n",
    "        tracks = sp.album_tracks(album)['items']            \n",
    "    except:\n",
    "        continue\n",
    "    for track in tracks:\n",
    "        song_id.append(track['id'])\n",
    "        song_name.append(track['name'])\n",
    "        song_artists.append([artist['name'] for artist in track['artists']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-management",
   "metadata": {},
   "source": [
    "Creating a pandas dataframe, and dropping duplicates, if the same track was in several albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "median-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>artists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5B38hxdKziEKVO0HO31wg7</td>\n",
       "      <td>Donizetti: Francesca di Foix: \"Senti senti ......</td>\n",
       "      <td>[Gaetano Donizetti, Antonello Allemandi, Londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2ZeKTqsCuQhqJpjFFbJvl9</td>\n",
       "      <td>Donizetti: Francesca di Foix: \"Quest'e il loco...</td>\n",
       "      <td>[Gaetano Donizetti, Antonello Allemandi, Londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>365ZW44z5LTdZ8RUC6b7eM</td>\n",
       "      <td>Donizetti: Francesca di Foix: \"Ecco il Conte ....</td>\n",
       "      <td>[Gaetano Donizetti, Antonello Allemandi, Londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3I1PR5GJ004cf0z7acH8SO</td>\n",
       "      <td>Donizetti: Francesca di Foix: \"Grato accolse i...</td>\n",
       "      <td>[Gaetano Donizetti, Antonello Allemandi, Londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1QZhXEa9R4Y4IesZQhbdIL</td>\n",
       "      <td>Donizetti: Francesca di Foix: \"Oh quale apport...</td>\n",
       "      <td>[Gaetano Donizetti, Antonello Allemandi, Londo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870010</th>\n",
       "      <td>11ZsxFaDHZDlhSeZO8KMgo</td>\n",
       "      <td>M.O.B.</td>\n",
       "      <td>[BlocBoy JB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870011</th>\n",
       "      <td>3aayNvTj79fO5HrWJtNAXx</td>\n",
       "      <td>T'd Off</td>\n",
       "      <td>[BlocBoy JB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870012</th>\n",
       "      <td>0FqlIQoWNeIQTy5flsd40b</td>\n",
       "      <td>Last Day Out</td>\n",
       "      <td>[BlocBoy JB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870013</th>\n",
       "      <td>6z9LOvbHFza6sWtPz2d8oZ</td>\n",
       "      <td>Lilium</td>\n",
       "      <td>[DJ Seinfeld]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11870014</th>\n",
       "      <td>51eDQb4i3VHdCVY944eNrH</td>\n",
       "      <td>Lovejoy</td>\n",
       "      <td>[DJ Seinfeld]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11870015 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  \\\n",
       "0         5B38hxdKziEKVO0HO31wg7   \n",
       "1         2ZeKTqsCuQhqJpjFFbJvl9   \n",
       "2         365ZW44z5LTdZ8RUC6b7eM   \n",
       "3         3I1PR5GJ004cf0z7acH8SO   \n",
       "4         1QZhXEa9R4Y4IesZQhbdIL   \n",
       "...                          ...   \n",
       "11870010  11ZsxFaDHZDlhSeZO8KMgo   \n",
       "11870011  3aayNvTj79fO5HrWJtNAXx   \n",
       "11870012  0FqlIQoWNeIQTy5flsd40b   \n",
       "11870013  6z9LOvbHFza6sWtPz2d8oZ   \n",
       "11870014  51eDQb4i3VHdCVY944eNrH   \n",
       "\n",
       "                                                       name  \\\n",
       "0         Donizetti: Francesca di Foix: \"Senti senti ......   \n",
       "1         Donizetti: Francesca di Foix: \"Quest'e il loco...   \n",
       "2         Donizetti: Francesca di Foix: \"Ecco il Conte ....   \n",
       "3         Donizetti: Francesca di Foix: \"Grato accolse i...   \n",
       "4         Donizetti: Francesca di Foix: \"Oh quale apport...   \n",
       "...                                                     ...   \n",
       "11870010                                             M.O.B.   \n",
       "11870011                                            T'd Off   \n",
       "11870012                                       Last Day Out   \n",
       "11870013                                             Lilium   \n",
       "11870014                                            Lovejoy   \n",
       "\n",
       "                                                    artists  \n",
       "0         [Gaetano Donizetti, Antonello Allemandi, Londo...  \n",
       "1         [Gaetano Donizetti, Antonello Allemandi, Londo...  \n",
       "2         [Gaetano Donizetti, Antonello Allemandi, Londo...  \n",
       "3         [Gaetano Donizetti, Antonello Allemandi, Londo...  \n",
       "4         [Gaetano Donizetti, Antonello Allemandi, Londo...  \n",
       "...                                                     ...  \n",
       "11870010                                       [BlocBoy JB]  \n",
       "11870011                                       [BlocBoy JB]  \n",
       "11870012                                       [BlocBoy JB]  \n",
       "11870013                                      [DJ Seinfeld]  \n",
       "11870014                                      [DJ Seinfeld]  \n",
       "\n",
       "[11870015 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'id':song_id,\n",
    "        'name':song_name,\n",
    "        'artists':song_artists\n",
    "        }\n",
    "songs = pd.DataFrame(data=data)\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "impressive-closing",
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = songs.drop_duplicates(subset='id')\n",
    "songs.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "committed-constitution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint:saving songs\n",
    "songs.to_csv(\"../data/checkpoints/songs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prompt-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst,n):\n",
    "    \"\"\"\n",
    "    Yields n-sized chunks of lst\n",
    "    \"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i+n]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "surrounded-interval",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_ids = songs['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-warren",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc5ac477d14f768e96d49198bd9889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/237401 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "audio_feats = []\n",
    "for chunk in tqdm(list(chunks(song_ids,50))):\n",
    "    try:\n",
    "        audio_feats.append(sp.audio_features(chunk))\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-utilization",
   "metadata": {},
   "source": [
    "we flatten this list into one long list of dictionaries, and turn it into a series, in order to use pandas.dropna(), so the conversion to data frame can easily work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_feats2 = pd.Series([y for x in audio_feats for y in x], name='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = pd.DataFrame(list(audio_feats2.dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painful-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint:saving features\n",
    "feat_df.to_csv(\"../data/checkpoints/feat_df.csv\")\n",
    "audio_feats2.to_csv(\"../data/checkpoints/audio_feats2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-ultimate",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = songs.merge(feat_df, on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worldwide-serve",
   "metadata": {},
   "source": [
    "We test that the merge worked properly using a random sample of 50, taking the audio features again, and comparing the value of danceability, for example in the resulting dataframe. The next cell will return true if there are matches, false if not "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = final.sample(50).reset_index()\n",
    "(pd.DataFrame(sp.audio_features(sample['id']))['danceability'] == sample['danceability']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-union",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"../data/checkpoints/Final dataframe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-petersburg",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-travel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
